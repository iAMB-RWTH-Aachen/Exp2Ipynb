{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of sequence to expression\n",
    "\n",
    "## Introduction\n",
    "The previous notebooks guide in the development of ML tools to predict the expression strength of a sequence. For practical purpose of bioengineering it is desirable to predict a sequence based on a target expression.\n",
    "\n",
    "## System initiation\n",
    "Loading all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from Exp2Ipynb import init_Exp2, Data_Src_Load, ExtractRefSeq, GeneOptimizer, toLetter, SequenceSinglePredFull, evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable setting\n",
    "\n",
    "We load the naming conventions from 'config.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existent data directory  data-Example1-Pput .\n"
     ]
    }
   ],
   "source": [
    "Name_Dict = init_Exp2('config_Pput.txt')\n",
    "\n",
    "File_Base = Name_Dict['Data_File'].split('.')[0]\n",
    "Data_Folder = 'data-{}'.format(File_Base) \n",
    "ML_Date = Name_Dict['ML_Date']\n",
    "ML_Regressor = Name_Dict['ML_Regressor'][:-1]\n",
    "ML_Type = Name_Dict['ML_Regressor'][-1]\n",
    "Y_Col_Name = eval(Name_Dict['Y_Col_Name'])\n",
    "Response_Value = eval(Name_Dict['Response_Value'])\n",
    "Measure_Numb = int(Name_Dict['Library_Expression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data and ML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following outliers were detected: ID: ['BGSPL14g_19_a'], Value: [[50.13234789]]\n",
      "Categorization of expression.\n",
      "The expression values were sorted into the following bins: [ 0.2178722  16.5660553  24.76999231 35.15239853]\n"
     ]
    }
   ],
   "source": [
    "# YCNum = 0\n",
    "# ML_TargetCol = '{}_ML'.format(Y_Col_Name[YCNum])\n",
    "# Measure_Name = ML_TargetCol\n",
    "# # loading correct ML regressor file and parameters for data preparation\n",
    "# Regressor_File = os.path.join(Data_Folder, '{}_{}_{}_{}{}-Regressor.pkl'.format(ML_Date, File_Base, Measure_Name.replace(' ','-'), ML_Regressor, Response_Value))\n",
    "# Parameter_File = os.path.join(Data_Folder, '{}_{}_{}_{}{}-Params.pkl'.format(ML_Date, File_Base, Measure_Name.replace(' ','-'), ML_Regressor, Response_Value))\n",
    "\n",
    "SeqDat = Data_Src_Load(Name_Dict)\n",
    "myRegr = dict()\n",
    "myParams = dict()\n",
    "\n",
    "for Meas_Idx in range(Measure_Numb): \n",
    "#     ML_TargetCol = '{}_ML'.format(Y_Col_Name[Meas_Idx])\n",
    "    Measure_Name = '{}_ML'.format(Y_Col_Name[Meas_Idx])\n",
    "    # loading correct ML regressor file and parameters for data preparation\n",
    "    Regressor_File = os.path.join(Data_Folder, '{}_{}_{}_{}{}-Regressor.pkl'.format(ML_Date, File_Base, Measure_Name.replace(' ','-'), ML_Regressor, Response_Value))\n",
    "    Parameter_File = os.path.join(Data_Folder, '{}_{}_{}_{}{}-Params.pkl'.format(ML_Date, File_Base, Measure_Name.replace(' ','-'), ML_Regressor, Response_Value))\n",
    "\n",
    "    try:\n",
    "    #         ML_DictName = (Measure_Name)\n",
    "        myRegr[Meas_Idx] = joblib.load(Regressor_File)\n",
    "        # I assume the parameters have been generated in the same run as the regressor itself and is located in the same directory following the default naming scheme\n",
    "        myParams = pickle.load(open(Parameter_File,'rb'))\n",
    "        # extracting the positions that were removed because of insufficient information content\n",
    "        Positions_removed = myParams['Positions_removed']\n",
    "        # if the data was standardized we load the corresponding function\n",
    "        if Response_Value == 0:\n",
    "            # loading standard scaler\n",
    "            Scaler_File = os.path.join(Data_Folder, '{}_{}_{}-Scaler.pkl'.format(time.strftime('%Y%m%d'), File_Base, Name_Dict['ML_Regressor']))\n",
    "            Expr_Scaler[Meas_Idx] = pickle.load(open(Scaler_File,'rb'))\n",
    "            # The standard scaler default name is the name of the expression measurement column with suffix: '_Scaler'\n",
    "            Scaler_DictName[Meas_Idx] = '{}_Scaler'.format(Y_Col_Name[Meas_Idx])\n",
    "    #             Expr_Scaler[Scaler_DictName] = Data_Prep_Params[Scaler_DictName]\n",
    "    except FileNotFoundError:\n",
    "        print('Regressor file not found. Check parameter \"ML_Date\" in \"config.txt\"')\n",
    "\n",
    "    # Save number of nucleotides the regressor uses as input, this is required to specifiy the number \n",
    "    # of optimization variables\n",
    "    # nNucleotides = myRegr.support_vectors_.shape[1] - 1\n",
    "    if Name_Dict['ML_Regressor'] == 'SVC' or Name_Dict['ML_Regressor'] == 'SVR':\n",
    "        nNucleotides = myRegr[Meas_Idx].support_vectors_.shape[1] - 1\n",
    "    else:\n",
    "        nNucleotides = myRegr[Meas_Idx].n_features_ - 1\n",
    "    \n",
    "nPositions = int(nNucleotides/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyRefs = ExtractRefSeq(SeqDat, Name_Dict, .05, 3)\n",
    "mytmp = np.delete(np.vstack(SeqDat['Sequence_label-encrypted'].values), Positions_removed, axis=1).tolist()\n",
    "mytst = mytmp[0]\n",
    "# mytst = list(np.ones(len(mytmp[0]), dtype=int))\n",
    "if mytst in mytmp:\n",
    "    print('exists')\n",
    "else:\n",
    "    print('new')\n",
    "mytst\n",
    "# SeqDat['Sequence_label-encrypted'].drop_duplicates().apply(tuple)\n",
    "# tuple()\n",
    "# from Exp2Ipynb import distance, GeneOptimizer\n",
    "# go = GeneOptimizer()\n",
    "# go\n",
    "# myseq = np.array(go._reference_sequences, ndmin=2, dtype=int)\n",
    "# distance(go._reference_sequences[0], go._reference_sequences)\n",
    "# go._reference_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg   \tstd    \tmin\tmax \n",
      "0  \t300   \t827.11\t373.235\t15 \t1000\n",
      "1  \t178   \t559.6 \t486.883\t15 \t1000\n",
      "2  \t159   \t200.457\t378.834\t10 \t1000\n",
      "3  \t195   \t65.03  \t206.877\t10 \t1000\n",
      "4  \t183   \t46.34  \t167.73 \t9  \t1000\n",
      "5  \t194   \t38     \t148.709\t9  \t1000\n",
      "6  \t176   \t29.5833\t126.358\t6  \t1000\n",
      "7  \t193   \t34.6067\t149.232\t5  \t1000\n",
      "8  \t205   \t26.3067\t126.782\t4  \t1000\n",
      "9  \t193   \t37.92  \t169.203\t4  \t1000\n",
      "10 \t171   \t46.58  \t194.623\t3  \t1000\n",
      "11 \t165   \t65.3267\t236.144\t3  \t1000\n",
      "12 \t170   \t81.2667\t264.739\t3  \t1000\n",
      "13 \t191   \t84.0467\t270.102\t3  \t1000\n",
      "14 \t148   \t70.42  \t248.442\t3  \t1000\n",
      "15 \t193   \t96.77  \t289.797\t3  \t1000\n",
      "16 \t175   \t63.2233\t236.674\t3  \t1000\n",
      "17 \t171   \t53.04  \t217.248\t3  \t1000\n",
      "18 \t181   \t46.3767\t202.96 \t3  \t1000\n",
      "19 \t168   \t29.7167\t160.604\t3  \t1000\n",
      "20 \t161   \t43.0633\t195.336\t3  \t1000\n",
      "21 \t185   \t43.0467\t195.338\t3  \t1000\n",
      "22 \t175   \t13.13  \t99.186 \t3  \t1000\n",
      "23 \t167   \t26.4867\t150.475\t3  \t1000\n",
      "24 \t174   \t33.0867\t170.046\t3  \t1000\n",
      "25 \t155   \t29.7633\t160.596\t3  \t1000\n",
      "26 \t189   \t49.6533\t210.264\t3  \t1000\n",
      "27 \t174   \t39.6967\t187.352\t3  \t1000\n",
      "28 \t165   \t39.6833\t187.354\t3  \t1000\n",
      "29 \t176   \t23.0333\t139.567\t3  \t1000\n",
      "30 \t168   \t36.3667\t178.943\t3  \t1000\n",
      "31 \t182   \t23.1267\t139.555\t3  \t1000\n",
      "32 \t187   \t46.3367\t202.968\t3  \t1000\n",
      "33 \t188   \t33.06  \t170.05 \t3  \t1000\n",
      "34 \t185   \t13.1067\t99.1884\t3  \t1000\n",
      "35 \t185   \t26.4233\t150.484\t3  \t1000\n",
      "36 \t164   \t23.09  \t139.56 \t3  \t1000\n",
      "37 \t190   \t46.3167\t202.972\t3  \t1000\n",
      "38 \t186   \t19.7467\t127.619\t3  \t1000\n",
      "39 \t181   \t29.7967\t160.591\t3  \t1000\n",
      "40 \t170   \t13.1967\t99.1804\t3  \t1000\n",
      "41 \t167   \t16.52  \t114.33 \t3  \t1000\n",
      "42 \t169   \t19.7967\t127.614\t3  \t1000\n",
      "43 \t190   \t19.7367\t127.62 \t3  \t1000\n",
      "44 \t194   \t19.8467\t127.608\t3  \t1000\n",
      "45 \t176   \t26.3767\t150.49 \t3  \t1000\n",
      "46 \t180   \t33.0733\t170.048\t3  \t1000\n",
      "47 \t175   \t19.8033\t127.612\t3  \t1000\n",
      "48 \t166   \t9.78333\t81.1237\t3  \t1000\n",
      "49 \t195   \t33.07  \t170.048\t3  \t1000\n",
      "50 \t173   \t29.7967\t160.591\t3  \t1000\n",
      "Target sequences saved as: data-Example1-Pput/20210324_Example1-Pput_Predicted-Target-Promoter_Promoter-Activity.csv\n"
     ]
    }
   ],
   "source": [
    "ExpressGoal = {0:[1]} #{0:[1], 1:[2]}\n",
    "ExpressFine = {0:[20]} #{0:[.03], 1:[.04]}\n",
    "ReferenceNumber = 2\n",
    "TargetNumber = 3\n",
    "MyFinal = pd.DataFrame({'Idx-Original':[], 'Strain-ID':[], 'Sequence':[], 'target':[]})\n",
    "# TargetSeqs = dict({'ID':[], 'Sequence':[], 'Expression': []})\n",
    "\n",
    "for Meas_Idx in ExpressGoal.keys(): \n",
    "#     Measure_Name = '{}_ML'.format(Y_Col_Name[Meas_Idx])\n",
    "    # extraction of reference sequences, closest expression with respect to ExpressFine input.\n",
    "    for iGoal, iFine in zip(ExpressGoal[Meas_Idx],ExpressFine[Meas_Idx]):\n",
    "        MyRefs = ExtractRefSeq(SeqDat, Name_Dict, iFine, ReferenceNumber)\n",
    "        go = GeneOptimizer()\n",
    "        myHOF, _ = go.optimize(myRegr[Meas_Idx], ML_Type, MyRefs, SeqDat, Positions_removed, nNucleotides, target_expr=iGoal, hof_size=TargetNumber)\n",
    "\n",
    "        myOptSeq = [''.join(SSeq) for SSeq in np.array([toLetter(Hofi) for Hofi in myHOF])]\n",
    "        myOptSeqFull = [SequenceSinglePredFull(OptSeq_i, MyRefs['Sequence'], Positions_removed) for OptSeq_i in myOptSeq]\n",
    "        myOptExpFull = [evaluation(hof_i, myRegr[Meas_Idx], nNucleotides) for hof_i in myHOF]\n",
    "        myID =['predicted:{}-{}'.format(iGoal,myCount) for myCount in range(1,TargetNumber+1)]\n",
    "        TarDict = {'Strain-ID':myID, 'Sequence':myOptSeqFull, 'target':myOptExpFull}\n",
    "\n",
    "        MyFinal = pd.concat([MyFinal, MyRefs, pd.DataFrame(TarDict)])\n",
    "\n",
    "    # MyFinal.reset_index()\n",
    "    Csv_ID = 'Predicted-Target-Promoter'\n",
    "    TarCsv_File = os.path.join('{}/{}_{}_{}_{}.csv'.format(Data_Folder, time.strftime('%Y%m%d'), File_Base, Csv_ID, Y_Col_Name[Meas_Idx].replace(' ','-')))\n",
    "    MyFinal.to_csv(TarCsv_File, index=None)\n",
    "    print('Target sequences saved as: {}'.format(TarCsv_File))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp2ipynb",
   "language": "python",
   "name": "exp2ipynb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
