{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ExpressionExpert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The ExpressionExpert.ipynb is a Jupyter notebook for the analysis of promoter libraries. The user uploads one or several sequence libraries with associated expression values. The notebook guides:\n",
    " 1. the statistical analysis, \n",
    " 2. the training of a random forest regressor,\n",
    " 3. the evaluation of the regressor performance,\n",
    " 4. the set-up of a synthetic promoter library within the experimental exploration region, and \n",
    " 5. the selection of new promoters with defined expression.\n",
    " \n",
    "--- \n",
    "## Workflow initialization\n",
    "The workflow is distributed in different notebooks. However, many functions call the same file and will store results in a common directory. In the following, a project directory is generated in combination with the file name of the promoter library. These informations are stored in the 'config.txt' file for all other notebooks. The config-file is evaluated in dedicated cells in the start of all Notebooks. Once initialized, you can also rename plots or names by changing the names in the config-file and then re-running notebooks 1-5.\n",
    "\n",
    "The code cell below generates a `config.txt` file. The important sensible user input is labeled between the '#' signs. Once you are fine with a given config-file, you can rename it and use the new config-file name in the approriate positions where the config-file is loaded in the other Notebooks.\n",
    "\n",
    "**User Input:** <br>\n",
    " * **Provide information starting from `Data_File` until `Synth_Seq_MaxNumber`.**\n",
    "\n",
    "*Example: <br>\n",
    "An example file for a promoter library in* Pseudomonas putida *KT2440 is provided.* <br>\n",
    "Data_File = 'liu_bacillus.csv'\n",
    "\n",
    "---\n",
    "**Author: Ulf Liebal** <br>\n",
    "**Institution: Institute of Applied Microbiology, RWTH Aachen** <br>\n",
    "**Contact: ulf.liebal@rwth-aachen.de** <br>\n",
    "**Date: 2020/07/01** <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "#####################\n",
    "# start User Input\n",
    "# File name of the library, in csv format\n",
    "# example input: 'Example1-Pput.csv', 'PromLib_EcolPtai.csv'\n",
    "Data_File = 'mutalik12_Ecol.csv' #'liu_bacillus.csv'  \n",
    "# Sequence column name\n",
    "Sequence = 'Short sequence'#'Sequence(5-3)'\n",
    "# column name of expression activity\n",
    "# example input: ['Promoter Activity'], ['Ecol Promoter Activity', 'Ptai Promoter Activity'],\n",
    "# Make sure all entries are within square brackets and hyphens\n",
    "Y_Col_Name = ['sE o/exp']#['GFP relative activity']\n",
    "# Promoter ID column name\n",
    "# 'Strain ID'\n",
    "ID_Col_Name = 'Promoter'#'Name'\n",
    "# expression unit for plots\n",
    "# example: '$\\mu$M(GFP)/(gCDW*h)' 'GFP intensity'\n",
    "Expression_Unit = 'Expression'#'GFP Activity'\n",
    "# Response value engineering\n",
    "# The machine learning to the expression can either take place on the original values, standardized values with zero mean and unit variance, or categorized expression values\n",
    "# Response_Value = 0: standardized expression with zero mean and unit variance\n",
    "# Response_Value = 1: expression as measured in the input\n",
    "# Response_Value = >1: categorized expression with bin number according to the value\n",
    "Response_Value = 3\n",
    "# the availabity of replicates improves regressor training, if your data is based on statistical summaries you can generate random samples with the same statistical properties, \n",
    "# you need to provide column names for standard deviation, the mean is assumed to be in Y_Col_Name\n",
    "# Stats_Samples contains column names with the number of replicates\n",
    "Stats2Samples = False\n",
    "Stats_Std = ['Error']\n",
    "Stats_Samples = ['Samples']\n",
    "# column for additional features, this particular feature is generated by the script\n",
    "Add_Feat = ['GC-content']\n",
    "# Reference Sequence for sequence diversity histogram\n",
    "# for X-Host 'GCCCATTGACAAGGCTCTCGCGGCCAGGTATAATTGCACG'\n",
    "RefSeq = ''\n",
    "# Machine learning approach for regression\n",
    "# choose RFR: random forest regression, GBR: gradient boosting regression, SVR: support vector regression\n",
    "ML_Regressor = 'RFR'\n",
    "# Kernal and function based machine learning approaches like SVM and artificial neural networks, require data standardization. Correlation and regression trees, including random forest, do not benefit from data standardization.\n",
    "# Set variable with Boolean for data standardization\n",
    "Data_Standard = False\n",
    "# if previously a synthetic library was generated it is stored under a generic name with only the date as variable\n",
    "# give synthetic library date to load file with default naming\n",
    "SynLib_Date = time.strftime('%Y%m%d')\n",
    "# Date for the random forest regression. \n",
    "ML_Date = time.strftime('%Y%m%d')\n",
    "# Test set cut-off, fraction of data removed from the original set to be used for quality assessment\n",
    "TestRatio = .1\n",
    "# Parameters for the synthetic promoter library\n",
    "# the 'Sequence_Distance_cutoff' determines how distant are sequences allowed to be different from the most common sequence reference\n",
    "# The statistical analysis gives a histogram of sequence distances, take an appropriate value from there\n",
    "# in Example1-Pput: 0.11\n",
    "Sequence_Distance_cutoff = .9\n",
    "# not all positions might be sampled with all nucleotides, the parameter 'Entropy_cutoff' determines the minimum position diversity\n",
    "# The position diversity entropy-bargraph gives an indication on the right parameter choice.\n",
    "# in Example1-Pput: 0.15\n",
    "Entropy_cutoff = .2\n",
    "# decide on how many synthetic promoters you want to simulate\n",
    "Synth_Seq_MaxNumber = 10000\n",
    "\n",
    "# end User Input\n",
    "#####################\n",
    "\n",
    "\n",
    "# extract the filename for naming of newly generated files\n",
    "# File_Base = Data_File.split('.')[0]\n",
    "# # the generated files will be stored in a subfolder with custom name\n",
    "# Data_Folder = 'data-{}'.format(File_Base)\n",
    "# try:\n",
    "#     os.mkdir(Data_Folder)\n",
    "#     print('Data directory ', Data_Folder, 'created.')\n",
    "# except FileExistsError:\n",
    "#     print('Already existent data directory ', Data_Folder, '.')\n",
    "\n",
    "# Definition of names\n",
    "# make specific changes prefereably in the user input space above.\n",
    "Name_Dict = {\n",
    "    'Data_File': Data_File,\n",
    "    # column name of sequence library\n",
    "    # if distinct sequence libraries were used for different expression measurement, then put names in a vector ['sequence1', 'sequence2']\n",
    "    'Sequence_column': Sequence,\n",
    "    # column name for the expression strength\n",
    "    # if more library expression measurements are conducted, then put Y_Col_Name in a vector ['name1', 'name2']\n",
    "    'Y_Col_Name': Y_Col_Name, # ['Promoter Activity'], ['Ecol Promoter Activity', 'Ptai Promoter Activity'],\n",
    "    # Promoter ID column name\n",
    "    'ID_Col_Name': ID_Col_Name,\n",
    "    # engineering of target value \n",
    "    'Response_Value': Response_Value,\n",
    "    # Decision whether to remove outlier from the data set\n",
    "    'Revome_Outlier': False,\n",
    "    # information for generating samples from statistics\n",
    "    'Stats2Samples': Stats2Samples,\n",
    "    'Stats_Std': Stats_Std,\n",
    "    'Stats_Samples': Stats_Samples,\n",
    "    # number of separate promoter libraries expression measurements\n",
    "    'Library_Expression': len(Y_Col_Name),\n",
    "    # column name for additional features input\n",
    "    'Add_Feat': Add_Feat,\n",
    "    # set the desired figure file type here, e.g. svg, png, pdf\n",
    "    'Figure_Type': 'png',\n",
    "    'HM_File': 'Plot_PositionNucleotideStats',\n",
    "    'SampSeqDist_File': 'Plot_SampleSequenceDistance',\n",
    "    'Entropy_File': 'Plot_PositionEntropy',\n",
    "    'SamplingDiv_File': 'Plot_SamplingDiversity',\n",
    "    'ExprHist_File': 'Plot_ExpressionHist',\n",
    "    'LogoPlot_File': 'Plot_Logo-FI',\n",
    "    'CorrPlot_File': 'Plot_Corr-Ytrue-VS-Ypred',\n",
    "    'Csv_ID': 'Synth-Library',\n",
    "    'X_Expr': 'Plot_CrossExpr',\n",
    "    'RefSeq': RefSeq,\n",
    "    'ML_Regressor': ML_Regressor,\n",
    "    'Data_Standard': Data_Standard,\n",
    "    'SynLib_Date': SynLib_Date,\n",
    "    'ML_Date': ML_Date,\n",
    "    # Machine learning files\n",
    "    'TestRatio': TestRatio,\n",
    "    'Expression_Unit': Expression_Unit,\n",
    "    # Parameters for the synthetic library\n",
    "    'Sequence_Distance_cutoff': Sequence_Distance_cutoff,\n",
    "    'Entropy_cutoff': Entropy_cutoff,\n",
    "    'Synth_Seq_MaxNumber': Synth_Seq_MaxNumber,\n",
    "    'Figure_Font_Size': 18\n",
    "}\n",
    "\n",
    "# constructing the config.txt file\n",
    "with open('config.txt', 'w') as f:\n",
    "    print('# {}'.format(time.strftime('%Y%m%d')), file=f)\n",
    "    print('# This file contains the naming conventions for all output files. It is automatically generated when going through step \"0-Workflow\".', file=f)\n",
    "    for key, value in Name_Dict.items():\n",
    "        print('{}: {}'.format(key, value), file=f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " \n",
    "## Statistical analysis \n",
    "\n",
    "The statistical analysis provides an overview to important properties of the promoter library. It visualizes the distribution of measured expression strength with a histogram. This is particularly informative if several promoter libraries are analysed in order to compare the coverage of expression strengths. It is important to delineate the sequence exploration space that has been spanned with the promoter library. The sequence exploration space defines the allowed sequence input for prediction of expression strength and limits the sequences for the generation of the synthetic promoter library. The exploratory space is identified by two properties: \n",
    " * the promoter library diversity, calculated by the percentage of nucleotide changes over the full sequence for all samples in the library, and \n",
    " * the position specific diversity, i.e. how many different nucleotides are sampled on each position, determined by the entropy on each position.\n",
    "\n",
    "The promoter diversity is visualized with a histogram of the frequency of sequences with a given number of nucleotide exchanges. The histogram shows how much nucleotides need to be changed to mutually convert sequences, and what is the maximum and average nucleotide differences. The entropy measurement of the position diversity informs about how many nucleotides have been sampled for each position.\n",
    "\n",
    "The promoter library with associated expression activities contains information how each nucleotide-position contributes to expression. This information is extracted by calculating the average and the variance of expression on each nucleotide position. The output is a heat-map that shows which positions are on average associated with higher or lower expression.\n",
    "\n",
    "[1-Statistical-Analysis.ipynb](./1-Statistical-Analysis.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Regressor training\n",
    "For random-forest regression, the data is split into a training and a test set, by default with a ratio of 9:1. The expression values are scaled to zero mean and unit variance based on the training set. Positions that are non-informative because no alternative nucleotides have been tested are deleted. The performance evaluation is based on the R^2 score from sklearn. The correlation of measured and predicted expression values is plotted. The feature importance from the random forest regression represent the contributions of each nucleotide-position to the prediction. They are extracted and visualized with a Logo-plot.\n",
    "\n",
    "[2-Regressor-Training.ipynb](./2-Random-Forest-Training.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation of regressor performance\n",
    "The goodness of a regressor is evaluated using the coefficient of correlation, R^2, and root mean squared error. Moreover, the trained feature importances from the random forest is visualized as a sequence logo to allow comparison with knwon regulatory elements.\n",
    "\n",
    "[3-Regressor-Performance.ipynb](./3-Regressor-Performance.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Generation of random sequences in the exploration space\n",
    "The generation of random sequences covered by the experimentally tested sequences serves to delineate the whole expected range of expression strength and to select for novel promoters with defined activity. The sequence exploration space is defined by the distance of nucleotide exchanges to a reference sequence and the information content for each nucleotide on all positions. Only if a position along the sequence has a sufficient information content can the conclusion be drawn that enough input diversity was present to learn a correct output mapping. The output mapping is determined with the position specific entropy and the user decides about the threshold of the entropy such that a position is being used for random sequence construction. The reference sequence can be pre-determined by the user or automatically assembled from the most common nucleotides at each position. The user has to identify the appropriate distance that the random sequences are allowed to be different from the reference. If the available sequences within the allowed exploration space is smaller than a threshold, all sequences will be generated, otherwise random sequences will be generated that satisfy the exploration space conditions. \n",
    "\n",
    "[4-Exploration-Space.ipynb](./4-Exploration-Space.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software dependencies\n",
    "\n",
    "CPython 3.7.6<br>\n",
    "IPython 7.12.0<br>\n",
    "<br>\n",
    "ipywidgets 7.5.1<br>\n",
    "matplotlib 3.1.3<br>\n",
    "numpy 1.18.1<br>\n",
    "pandas 1.0.1<br>\n",
    "sklearn 0.22.1<br>\n",
    "scipy 1.4.1<br>\n",
    "logomaker 0.8<br>\n",
    "joblib 0.14.1<br>\n",
    "<br>\n",
    "compiler   : GCC 7.3..<br>\n",
    "system     : Linux<br>\n",
    "release    : 5.3.0-53-generic<br>\n",
    "machine    : x86_64<br>\n",
    "processor  : x86_64<br>\n",
    "CPU cores  : 8<br>\n",
    "interpreter: 64bit<br>\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p ipywidgets,matplotlib,numpy,pandas,sklearn,scipy,logomaker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
